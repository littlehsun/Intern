{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import time\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def content(url2):        \n",
    "    b = open(url2.split('/')[-1].split('.')[0] + '.txt','w')\n",
    "    page = requests.get(url2)\n",
    "    tree2 = html.fromstring(page.text)\n",
    "    a = ''\n",
    "    if url2.split('/')[-2]=='article':\n",
    "        if url2.split('/')[2].split('.')[0]=='travel':\n",
    "            for i in tree2.xpath('//div[@class=\"date\"]/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 + '\\n'\n",
    "            for i in tree2.xpath('//div[@class=\"story\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 \n",
    "        elif url2.split('/')[2].split('.')[0]=='game':\n",
    "            for i in tree2.xpath('//div[@class=\"txt_2\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 + '\\n'\n",
    "            for i in tree2.xpath('//div[@class=\"story\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 \n",
    "    else:\n",
    "        for i in tree2.xpath('//span[@class=\"news-time\"]/text()'):\n",
    "            str1 = str(i.encode('utf-8'))\n",
    "            a = a + str1 + '\\n'\n",
    "        for i in tree2.xpath('//div[@class=\"story\"]/sectione/p/text()'):\n",
    "            str1 = str(i.encode('utf-8'))\n",
    "            a = a + str1 + '\\n'\n",
    "    b.write(a)\n",
    "    b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getcontent():\n",
    "    url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    \n",
    "    for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "        k=0\n",
    "        for j in i:\n",
    "            k=k+1\n",
    "            if k%3==0:\n",
    "                url2 = str(j.get('href'))\n",
    "                content(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timer1(t):\n",
    "    count = 0\n",
    "    looper = 500\n",
    "    while(looper != 0):\n",
    "        count = count +1\n",
    "        print '**************'+str(count)+'*************'\n",
    "        getcontent()\n",
    "        time.sleep(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timer1(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.text)\n",
    "    \n",
    "for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "    k=0\n",
    "    for j in i:\n",
    "        k=k+1\n",
    "        if k%3==0:\n",
    "            url2 = str(j.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.text)\n",
    "for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "    for j in i:\n",
    "        url2 = str(j.get('href'))\n",
    "        print url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getcontent():\n",
    "    url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.text)\n",
    "    \n",
    "    for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "        k=0\n",
    "        for j in i:\n",
    "                k=k+1\n",
    "                if k%3==0:\n",
    "                    url2 = str(j.get('href'))\n",
    "                if k%3==2:\n",
    "                    for a in tree2.xpath('//div[@class=\"part_list_1\"]/h3/em/test()'):\n",
    "                        cl = str(a.encode('utf-8'))\n",
    "        content(url2,cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def content(url2,cl):        \n",
    "    b = open(url2.split('/')[-1].split('.')[0] + '.txt','w')\n",
    "    page = requests.get(url2)\n",
    "    tree2 = html.fromstring(page.text)\n",
    "    a = ''\n",
    "    if url2.split('/')[-2]=='article':\n",
    "        if url2.split('/')[2].split('.')[0]=='travel':\n",
    "            for i in tree2.xpath('//div[@class=\"date\"]/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 + '\\n'\n",
    "            for i in tree2.xpath('//div[@class=\"story\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 \n",
    "        elif url2.split('/')[2].split('.')[0]=='game':\n",
    "            for i in tree2.xpath('//div[@class=\"txt_2\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 + '\\n'\n",
    "            for i in tree2.xpath('//div[@class=\"story\"]/p/text()'):\n",
    "                str1 = str(i.encode('utf-8'))\n",
    "                a = a + str1 \n",
    "    else:\n",
    "        for i in tree2.xpath('//span[@class=\"news-time\"]/text()'):\n",
    "            str1 = str(i.encode('utf-8'))\n",
    "            a = a + str1 + '\\n'\n",
    "        for i in tree2.xpath('//div[@class=\"story\"]/sectione/p/text()'):\n",
    "            str1 = str(i.encode('utf-8'))\n",
    "            a = a + str1 + '\\n'\n",
    "    b.write(a)\n",
    "    b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.text)\n",
    "    \n",
    "for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "    k=0\n",
    "    for j in i:\n",
    "        k=k+1\n",
    "        if k%3==0:                \n",
    "            url2 = str(j.get('href'))\n",
    "        if k%3==2:                    \n",
    "            for a in tree2.xpath('//div[@class=\"part_list_1\"]/h3/em/test()'):\n",
    "                cl = str(a.encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.text)\n",
    "    \n",
    "for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "    k=0\n",
    "    for j in i:\n",
    "        k=k+1\n",
    "        if k%3==0:\n",
    "            url2 = str(j.get('href'))\n",
    "            print url2\n",
    "\n",
    "url = 'http://www.ettoday.net/news/news-list.htm'\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.text)\n",
    "    \n",
    "for i in tree.xpath('//div[@class=\"part_list_1\"]/h3'):\n",
    "    k=0\n",
    "    for j in i:\n",
    "        k=k+1\n",
    "        if k%3==0:\n",
    "            url2 = str(j.get('href'))\n",
    "            print url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
